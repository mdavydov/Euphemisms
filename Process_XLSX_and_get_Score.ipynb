{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sx2xkX3SJSmO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kb4-1YAgQUkj"
      },
      "outputs": [],
      "source": [
        "def read_sheet(df : pd.DataFrame, labels, ai_labels):\n",
        "  num = df.shape[0]\n",
        "  #print(num)\n",
        "  #strings = clean_strings(df.loc[0:num, 'text'])\n",
        "  labels.extend(np.array( df.loc[0:num, 'label'], np.int8))\n",
        "  ai_labels.extend(np.array( df.loc[0:num, 'ai_label'], np.int8))\n",
        "  assert(len(labels)==len(ai_labels))\n",
        "  #print(len(labels), ' ', len(ai_labels))\n",
        "  #array = process_with_ai(strings, labels, model_name)\n",
        "  #print(array)\n",
        "  #df['ai_label'] = array\n",
        "  #df.loc[0, 'text'] = \"New Text\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJ4UeFRkKd2n"
      },
      "outputs": [],
      "source": [
        "#model = 'gpt-4o'\n",
        "\n",
        "def model_stat(model):\n",
        "  xls = pd.ExcelFile(f'Result_Ukr-{model}.xlsx')\n",
        "\n",
        "  # Display available sheet names\n",
        "  #print(\"Sheet names:\", xls.sheet_names)\n",
        "\n",
        "  dfs = pd.read_excel(xls, sheet_name=None)\n",
        "  labels = []\n",
        "  ai_labels = []\n",
        "  # Read and display all sheets\n",
        "  for sheet in xls.sheet_names:\n",
        "    if sheet=='Examples':\n",
        "      continue\n",
        "    try:\n",
        "      #print(f\"\\nProcessing sheet: {sheet}\")\n",
        "      read_sheet(dfs[sheet], labels, ai_labels)\n",
        "    except:\n",
        "      print(f\"Error while processing {sheet}\")\n",
        "\n",
        "\n",
        "  labels = np.int8(labels)\n",
        "  ai_labels = np.int8(ai_labels)\n",
        "  tp = ((labels==1) & (ai_labels==1)).sum()\n",
        "  fp = ((labels==0) & (ai_labels==1)).sum()\n",
        "  tn = ((labels==0) & (ai_labels==0)).sum()\n",
        "  fn = ((labels==1) & (ai_labels==0)).sum()\n",
        "  precision = tp/(tp+fp)\n",
        "  recall = tp/(tp+fn)\n",
        "  f1 = 2*precision*recall/(precision+recall)\n",
        "\n",
        "  print(f'{model};{tp};{fp};{tn};{fn};{precision};{recall};{f1}')\n",
        "\n",
        "  # Save all modified sheets back\n",
        "  #with pd.ExcelWriter(f'Result_Ukr-{model_name}.xlsx') as writer:\n",
        "  #    for sheet_name, df in dfs.items():\n",
        "  #        df.to_excel(writer, sheet_name=sheet_name, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJkmW8t3bVYU",
        "outputId": "f4bc957a-6ff0-47b2-c5c9-2a609476549f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model;tp;fp;tn;fn;precision;recall;f1\n",
            "deepseek-chat-2;2573;1209;440;352;0.680327868852459;0.8796581196581197;0.7672580885641866\n"
          ]
        }
      ],
      "source": [
        "models = [\n",
        "    #\"gpt-4o-13\",\n",
        "    \"deepseek-chat-2\",\n",
        "    #\"deepseek-chat-h\",\n",
        "    #\"deepseek-chat-voc3\",\n",
        "    #\"deepseek-chat-word-list\",\n",
        "    #\"gpt-4o-mini-h\",\n",
        "    #\"gpt-4o-mini-voc3\",\n",
        "    #\"gpt-4o-mini-word-list\",\n",
        "    #\"gpt-4o-h\",\n",
        "    #\"gpt-4o-voc3\",\n",
        "    #\"gpt-4o-word-list\",\n",
        "    #-----\n",
        "    #\"gpt-4o-mini-voc\",  # synonyms and hyperonims + vocabulary\n",
        "    #\"gpt-4o-mini-voc2\",  # synonyms and hyperonims + vocabulary(2nd prompt)\n",
        "    #\"gpt-4o-mini-4\",  # synonyms and hyperonims + vocabulary(3rd prompt) (euphemisms in context of war)\n",
        "    #\"gpt-4o-mini-7\",  # synonyms and hyperonims\n",
        "    #\"gpt-4o-mini-1by1\",\n",
        "    #\"gpt-4o-mini-1by1-eng\",\n",
        "    #\"gpt-4o-1by1\"\n",
        "    #\"gpt-4o\",\n",
        "    #\"gpt-4o-voc3\",\n",
        "    #\"gpt-4o-7\", # 5 first sentences from each page where used as training examples\n",
        "    #\"gpt-4o-8\", # 10 first sentences from each page where used as training examples\n",
        "    #\"gpt-4o-6\", # sentences from \"Example\" page where used as training examples\n",
        "    #\"gpt-4o-mini\",\n",
        "    #\"gpt-4o-mini-2\", # 5 first examples from every page were taken as training\n",
        "    #\"gpt-4o-mini-3\",\n",
        "    #\"gpt-4o-mini-6\", # 5 first examples from every page were taken as training\n",
        "    #\"gpt-4o-mini-4\", # 10 first examples from every page were taken as training\n",
        "    #\"gpt-4o-mini-5\", # sentences from \"Example\" page were taken as training\n",
        "    #\"gpt-4-turbo\",\n",
        "    #\"gpt-4\",\n",
        "    #\"gpt-3.5-turbo\"\n",
        "]\n",
        "\n",
        "print('model;tp;fp;tn;fn;precision;recall;f1')\n",
        "\n",
        "with warnings.catch_warnings(action=\"ignore\"):\n",
        "  for model_name in models:\n",
        "    model_stat(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AmFS-sUimMXb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}